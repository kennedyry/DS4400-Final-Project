{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "\n",
    "\n",
    "## TODO: \n",
    "    * Work on aggregating the title.akas DF. Each movie has multiple rows so we need to determine how we want to \n",
    "      merge this into our main one as each movie will have multiple entries \n",
    "    * Work on merging the list of actors into our list. Need to get a list of the actors for a given movie, merge it, \n",
    "      then one-hot encode it. \n",
    "    * Figure out how to featurize the movie title, maybe NLP vector would be the best but thats somewhat complicated \n",
    "      Could do things like length of the title, whether it contains nouns, etc. \n",
    "\n",
    "This notebook contains the relevant code for aggregating our CSV's into a singular one that can then be used in our models. \n",
    "\n",
    "Contains the One-Hot encoding, and featurization of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "#Descriptions of sets available at https://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded title.ratings\n",
      "Loaded title.principals\n"
     ]
    }
   ],
   "source": [
    "# Loading the Sets: \n",
    "sets = {} \n",
    "\n",
    "for file in os.listdir('DataSets'):\n",
    "    file = file.replace('.tsv', '') \n",
    "    sets[file] = pd.read_csv(f\"DataSets/{file}.tsv\", sep='\\t')\n",
    "    if 'tconst' in sets[file].keys():\n",
    "        sets[file].set_index('tconst',inplace=True)\n",
    "    elif 'titleId' in sets[file].keys():\n",
    "        sets[file].set_index('titleId', inplace=True) \n",
    "    else:\n",
    "        print(\"Cant set index for \", file)\n",
    "    print(f\"Loaded {file}\")\n",
    "print(\"Loaded all datasets\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we need from each dataset: \n",
    "### title.akas \n",
    "    * Language\n",
    "    * region \n",
    "### title.basics\n",
    "    * titleType -> Used to only keep movies, used in filtering. We should filter before we split, etc. \n",
    "    * primaryTitle -> We only care about the most popular title so use this one \n",
    "    * isAdult -> Why not include these \n",
    "    * startYear -> Year movie released, good to see to potentially capture trends of a timeperiod \n",
    "    * runtimeMinutes -> Good to know for how long a movie is \n",
    "    * genres -> One hot encoding on the genres it has \n",
    "### title.crew \n",
    "    * directors -> One hot encoding on top 100 directors \n",
    "    * writers -> One hot encoding on top 100 writers \n",
    "### title.episode \n",
    "    * We dont care about episodes so skip this one \n",
    "### title.principals  - Info about cast / crew for titles \n",
    "    * nconst -> Useful for determining which actor is who. Can use this with one-hot encoding for each movie to \n",
    "                determine top 100 actors and whether or not they were in a movie or not \n",
    "### title.ratings \n",
    "    * averageRating -> Weight average of all individual ratings, used as our target variable \n",
    "    * numVotes -> The number of votes it received - useful to somehow include this in our target, would want to \n",
    "                  weight training samples with move votes w/ more importance, can be used with models that allow that \n",
    "### name.basics\n",
    "    * Can potentially include this later on in our featurizations if we need info about the people, currently I think \n",
    "      just their unique id from title.principals should be more than enough to capture actors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: \n",
    "    1) First get ids of all entries that are movies (So we are not including things that arent movies) \n",
    "    \n",
    "    2) Then filter the raitings CSV to only include just movies, then move to actually just only keep the first X number of movies with a certain raitings count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DFs we have loaded: \", sets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILTERING SO WE ONLY HAVE MOVIES: \n",
    "df = sets['title.basics']\n",
    "\n",
    "# Keep only the rows that have a titleType of movie\n",
    "df = df[df['titleType'] == 'movie']\n",
    "\n",
    "# The row ids that are just movies \n",
    "movie_ids = list(df.index)\n",
    "#first 10 just to make sure its ids \n",
    "print(movie_ids[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting over to the title.ratings CSV to get the first X number of movies with the most reviews \n",
    "df = sets['title.ratings']\n",
    "\n",
    "#Filtering the df to only include the ids that were explicitly movies \n",
    "df = df.loc[movie_ids]\n",
    "\n",
    "# Sorting the df by numVotes so its from most number of reviews -> less \n",
    "df.sort_values(by='numVotes', inplace=True, ascending=False)\n",
    "# I dont know why I hardcoded these but checks 100k to 20k in batches of 10k  \n",
    "for splitter in [100000, 90000, 80000, 70000, 60000, 50000, 40000, 30000, 20000]:\n",
    "    top = list(df['numVotes'][:splitter])\n",
    "    print(f\"Total number of movies: {splitter} : Lowest raiting count: {top[-1]}\")\n",
    "\n",
    "\n",
    "# We will go with 30k for now to keep it simple :) \n",
    "TOTAL_MOVIES_TO_KEEP = 30000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ids that meet the criteria we are utilizing now in our main df. \n",
    "movie_ids = list(df['numVotes'][:TOTAL_MOVIES_TO_KEEP].index)\n",
    "# Filter the DataFrame to only keep those ids :) \n",
    "print(df.shape)\n",
    "df = df.loc[movie_ids]\n",
    "print(df.shape)\n",
    "\n",
    "# Our output final df, named final_df for ease. Contains the top 30k movies for the number of votes. \n",
    "final_df = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORING AKA RIGHT NOW AS IT HAS DUPLICATES SO WE NEED TO FIGURE OUT WHETHER TO AGGREGATE OR NOT\n",
    "\n",
    "# If we ever need to change the columns we are merging into it, do so here :) \n",
    "AKA_COLS = ['region', 'language'] \n",
    "BASICS_COLS = ['primaryTitle', 'isAdult', 'startYear', 'runtimeMinutes', 'genres']\n",
    "\n",
    "# Grab the respective dfs, only grab the rows that are our movie ids we have chosen to work with \n",
    "df_aka = sets['title.akas'].loc[movie_ids]\n",
    "df_basic = sets['title.basics'].loc[movie_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the dfs to only be the columns we are actually interested in \n",
    "df_aka = df_aka[AKA_COLS]\n",
    "df_basic = df_basic[BASICS_COLS]\n",
    "\n",
    "# Merging AKA and Basic  - ignoring right now \n",
    "# merged = df_aka.join(df_basic)\n",
    "\n",
    "# Joining the merged above df into our final df \n",
    "# final_df = final_df.join(merged) \n",
    "\n",
    "final_df = final_df.join(df_basic) \n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREW_COLS = ['directors','writers']\n",
    "# Merging The Crew df into our main Df: Should probably do one hot encoding here before we actually merge it but idk \n",
    "crew = sets['title.crew'].loc[movie_ids]\n",
    "crew = crew[CREW_COLS]\n",
    "\n",
    "final_df = final_df.join(crew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs the top X number of categories, defaulted to 100. Utilized by our one-hot encoding system to\n",
    "# determine what the most used number of categories are \n",
    "def top_categories(df, col_name, TOTAL_TO_KEEP = 100):\n",
    "    \"\"\"\n",
    "        Provided a dataframe and the column name, returns the top 100 categories for this column \n",
    "        @param df: The DataFrame we are searching over \n",
    "        @param col_name: The column name we are examining the categories for \n",
    "        @param TOTAL_TO_KEEP: Constant specifying the total number of entries to keep. \n",
    "        :return A list of the top 100 categories for this column. \n",
    "    \"\"\"\n",
    "    frequencies = {}\n",
    "    for entry in list(df[col_name]):\n",
    "        # If we have a list of items iterate over each of them \n",
    "        if not isinstance(entry, str) and isinstance(entry, list):\n",
    "            for entry_sub in entry:\n",
    "                if entry_sub in frequencies:\n",
    "                    frequencies[entry_sub] += 1\n",
    "                else:\n",
    "                    frequencies[entry_sub] = 1 \n",
    "        else:\n",
    "            # Just a singular item so can compare it here directly. \n",
    "            if entry in frequencies:\n",
    "                frequencies[entry] += 1\n",
    "            else:\n",
    "                frequencies[entry] = 1 \n",
    "    \n",
    "    lof_frequencies = []\n",
    "    for key in frequencies.keys():\\\n",
    "        lof_frequencies.append( (key, frequencies[key]) )\n",
    "    lof_frequencies.sort(key = (lambda pair: pair[1]))\n",
    "        \n",
    "    return [pair[0] for pair in lof_frequencies[:TOTAL_TO_KEEP]]\n",
    "\n",
    "\n",
    "def encode_row(row, category):\n",
    "    \"\"\"\n",
    "        Encodes a specific row / entry in our dataframe. If the row is a list, checks to see if the \n",
    "        category value exists in it, if it is not a list just checks to see if the row is equal to the category \n",
    "    \"\"\"\n",
    "    if not isinstance(row, str) and isinstance(row, list):\n",
    "        return 1 if category in row else 0 \n",
    "    else:\n",
    "        return 1 if category == row else 0 \n",
    "\n",
    "def encode_non_categorical_row(row, lof_categories):\n",
    "    \"\"\"\n",
    "        Encodes a row specifically looking to see if the value is not in our list of categories. If any of the \n",
    "        values does not exist in our list of categories return 1, else 0 \n",
    "    \"\"\"\n",
    "    if not isinstance(row, str) and isinstance(row, list):\n",
    "        for value in row:\n",
    "            if value not in lof_categories:\n",
    "                return 1 \n",
    "        return 0 \n",
    "    else: \n",
    "        return 1 if row not in lof_categories else 0 \n",
    "\n",
    "# Converts a specific column to a one-hot encoding version of it.\n",
    "def encode_column(df, col_name, TOTAL_TO_KEEP = 100):\n",
    "    df = df.copy()\n",
    "    \"\"\"\n",
    "        Provided a dataframe and column to encode, mutates a copy of the dataframe to have that a one-hot encoding of that \n",
    "        specific column. Will remove that specific column from the dataframe and replace it with TOTAL_TO_KEEP \n",
    "        columns for that value plus one more column to handle any categorical variable that was not in the top \n",
    "        TOTAL_TO_KEEP categories. \n",
    "        \n",
    "        @param df: The dataframe we are mutating \n",
    "        @param col_name: The column we are encoding, this column is removed from the df and replaced with the encodings\n",
    "        @param TOTAL_TO_KEEP: Number of categories we want to display, defaulted to 100 \n",
    "        :return A Copy of the dataframe with the encoding \n",
    "    \"\"\"\n",
    "    categories = top_categories(df, col_name, TOTAL_TO_KEEP=TOTAL_TO_KEEP)\n",
    "    \n",
    "    # Our encoded columns for the dataset goes here \n",
    "    encoded_cols = {}\n",
    "    \n",
    "    lof_column = list(df[col_name])\n",
    "    \n",
    "    for category in categories: \n",
    "        encoded_column = [encode_row(row, category) for row in lof_column]\n",
    "        \n",
    "        encoded_col_name = f\"{col_name}_{category}\"\n",
    "        df[encoded_col_name] = encoded_column\n",
    "    # If any of the entries is not in our lof-categories featurize this under the non_100 category \n",
    "    df[f\"{col_name}_non_100_category\"] = [encode_row(row, categories) for row in lof_column]\n",
    "    df.drop(columns=[col_name], inplace=True)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Dont run one-hot encoding on the title / movie title, find different way to featurize this. \n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic demonstration of one-hot encoding. If a columns values are strings we run one-hot encoding on it \n",
    "for col in final_df.keys():\n",
    "    if isinstance(list(final_df[col])[0], str):\n",
    "        final_df = encode_column(final_df, col)\n",
    "\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
